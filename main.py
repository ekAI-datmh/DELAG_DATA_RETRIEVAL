import ee
import os
import rasterio
from rasterio.warp import transform_bounds
from lst_retrieval import lst_retrive
from ls2_prd_retrieval import main_ls2prd_lst
from rvi_retrieval import main_rvi
from ndvi_retrieval import main_ndvi
from era5_retriever import main as era5_download
from gldas21_retriever import download_gldas_lsts as gldas_download
from fldas_retriever import download_fldas as fldas_download
import pandas as pd
import math
import glob
from concurrent.futures import ThreadPoolExecutor, as_completed


def get_region_coordinates(tif_file_path):
    """
    Opens a GeoTIFF file and returns the coordinates of its bounds as a list of
    [lon, lat] pairs in EPSG:4326, ordered counter-clockwise.
    [bottom-left, bottom-right, top-right, top-left, bottom-left]
    """
    with rasterio.open(tif_file_path) as dataset:
        # Transform bounds to EPSG:4326 (lat/lon)
        bounds = transform_bounds(dataset.crs, 'EPSG:4326', *dataset.bounds)
        
        # Create coordinates list in CCW order for ee.Geometry.Polygon.
        # bounds = (min_lon, min_lat, max_lon, max_lat)
        coordinates = [
            [bounds[0], bounds[1]],  # Bottom-left
            [bounds[2], bounds[1]],  # Bottom-right
            [bounds[2], bounds[3]],  # Top-right
            [bounds[0], bounds[3]],  # Top-left
            [bounds[0], bounds[1]]   # Closing the loop
        ]
        return coordinates

def read_rois_from_csv(csv_file_path):
    """
    Reads ROI information from a CSV file generated by filter_tay_nguyen_grids.py
    and creates ee.Geometry.Polygon objects for each ROI.
    
    Args:
        csv_file_path (str): Path to the CSV file containing filtered grid results
        
    Returns:
        dict: A dictionary where keys are ROI names and values are ee.Geometry.Polygon objects.
    """
    try:
        df = pd.read_csv(csv_file_path)
        print(f"Successfully read CSV file: {csv_file_path}")
        print(f"Found {len(df)} ROIs in the CSV file")
    except FileNotFoundError:
        print(f"Error: CSV file not found at {csv_file_path}")
        return {}
    except Exception as e:
        print(f"Error reading CSV file {csv_file_path}: {e}")
        return {}
    
    roi_geometries = {}
    required_columns = ['grid_id', 'center_longitude', 'center_latitude', 'width_degrees', 'height_degrees']
    
    if not all(col in df.columns for col in required_columns):
        print(f"Error: CSV file is missing required columns: {required_columns}")
        print(f"Available columns: {df.columns.tolist()}")
        return {}
    
    print("Creating ROI geometries from CSV data...")
    for index, row in df.iterrows():
        try:
            grid_id = str(row['grid_id'])
            center_lon = float(row['center_longitude'])
            center_lat = float(row['center_latitude'])
            width_deg = float(row['width_degrees'])
            height_deg = float(row['height_degrees'])
            
            # Validate coordinates
            if not (-180 <= center_lon <= 180):
                print(f"Warning: Invalid longitude {center_lon} for grid {grid_id}. Skipping.")
                continue
            if not (-90 <= center_lat <= 90):
                print(f"Warning: Invalid latitude {center_lat} for grid {grid_id}. Skipping.")
                continue
            
            # Calculate bounding box coordinates
            min_lon = center_lon - (width_deg / 2)
            max_lon = center_lon + (width_deg / 2)
            min_lat = center_lat - (height_deg / 2)
            max_lat = center_lat + (height_deg / 2)
            
            # Create ROI name
            roi_name = f"TayNguyen_{grid_id}"
            
            # Create coordinates in counter-clockwise order for ee.Geometry.Polygon
            coords_4326 = [
                [min_lon, min_lat],  # Bottom-left
                [max_lon, min_lat],  # Bottom-right
                [max_lon, max_lat],  # Top-right
                [min_lon, max_lat],  # Top-left
                [min_lon, min_lat]   # Close the loop
            ]
            
            # Create ee.Geometry.Polygon object
            geometry = ee.Geometry.Polygon(
                coords=coords_4326,
                proj='EPSG:4326',
                geodesic=False,
                evenOdd=True
            )
            
            roi_geometries[roi_name] = geometry
            
            if index < 10:  # Print first 5 for verification
                print(f"  - Created ROI: {roi_name} - Center: ({center_lon:.6f}, {center_lat:.6f}), "
                      f"Size: {width_deg:.6f}° x {height_deg:.6f}°")
                
        except ValueError as ve:
            print(f"Skipping row {index+1} (grid_id: {row.get('grid_id', 'N/A')}) due to data type error: {ve}")
        except Exception as e:
            print(f"Error processing row {index+1} for grid_id {row.get('grid_id', 'N/A')}: {e}")
    
    print(f"Successfully created {len(roi_geometries)} ROI geometries from CSV")
    return roi_geometries

def discover_rois_from_sample_folder(sample_folder):
    """
    Discovers ROIs by scanning for subdirectories in the sample_folder.
    Each subdirectory is an ROI. The geometry is derived from the first .tif
    file found inside the 'lst' subfolder of each ROI folder.
    Expected structure: sample_folder/{ROI_NAME}/lst/*.tif

    Args:
        sample_folder (str): The folder containing ROI subdirectories.

    Returns:
        dict: A dictionary where keys are ROI names and values are ee.Geometry.Polygon objects.
    """
    if not os.path.isdir(sample_folder):
        print(f"Error: Sample folder not found at {sample_folder}")
        return {}

    roi_geometries = {}
    print(f"Scanning for ROIs in: {sample_folder}")
    # List all subdirectories in the sample_folder; these are the ROIs.
    for roi_name in os.listdir(sample_folder):
        roi_path = os.path.join(sample_folder, roi_name)
        if os.path.isdir(roi_path):
            # The .tif files are inside an 'lst' subfolder.
            lst_folder_path = os.path.join(roi_path, 'lst')
            
            if not os.path.isdir(lst_folder_path):
                print(f"  - Warning: 'lst' subfolder not found for ROI '{roi_name}'. Skipping.")
                continue

            tif_file = None
            # Find the first .tif file in the 'lst' subfolder.
            for filename in os.listdir(lst_folder_path):
                if filename.lower().endswith('.tif'):
                    tif_file = os.path.join(lst_folder_path, filename)
                    break
            
            if tif_file:
                try:
                    print(f"  - Found ROI '{roi_name}' using sample: {os.path.basename(tif_file)}")
                    coords_4326 = get_region_coordinates(tif_file)
                    geometry = ee.Geometry.Polygon(
                        coords=coords_4326,
                        proj='EPSG:4326',
                        geodesic=False
                    )
                    roi_geometries[roi_name] = geometry
                except Exception as e:
                    print(f"    Error processing tif for ROI {roi_name}: {e}")
            else:
                print(f"  - Warning: No .tif files found in 'lst' folder for ROI '{roi_name}'. Skipping.")
    
    return roi_geometries

def read_region_coordinates(folder_path):
    """
    Reads all TIFF images in the given folder (ignoring non-TIF files), extracts the region name
    from the file name, gets the image bounds, and returns a dictionary with keys as region names
    and values as the coordinates (in EPSG:3857) of that image.
    
    Assumes file names have the format:
    "RegionName_lst16days_YYYY-MM-DD.tif"
    
    For example, for "Giao_Lac_lst16days_2022-12-20.tif", the region name is "Giao_Lac".
    """
    region_dict = {}
    # Loop over all files in the folder.
    for filename in os.listdir(folder_path):
        if filename.lower().endswith(".tif"):
            # Extract region name by splitting on "_lst16days"
            region_name = filename.split("_lst16days")[0].replace("_", "") + "_DucCo_GiaLai"
            print(region_name)
            tif_file_path = os.path.join(folder_path, filename)
            try:
                coordinates = get_region_coordinates(tif_file_path)
                region_dict[region_name] = coordinates
            except Exception as e:
                print(f"Error processing file {filename}: {e}")
    return region_dict

# Example usage:
# folder_path = "/mnt/data1tb/LSTRetrieval/Code/LST"  # Replace with your folder path
# regions = read_region_coordinates(folder_path)
# print(regions)


def read_rois_from_excel(excel_file_path, kv_type_prefix):
    """
    Reads an Excel file to extract ROI information and returns a dictionary
    of ROI names to ee.Geometry.Polygon objects.

    The Excel file must contain columns: 'Box_ID', 'Longitude', 'Latitude',
    'Width_degrees', 'Height_degrees'.

    Args:
        excel_file_path (str): Path to the Excel file.
        kv_type_prefix (str): Prefix for ROI name (e.g., "220kV" or "500kV").

    Returns:
        dict: Dictionary where keys are ROI names (e.g., "220kV_Box1")
              and values are ee.Geometry.Polygon objects in EPSG:4326, planar.
    """
    try:
        df = pd.read_excel(excel_file_path)
    except FileNotFoundError:
        print(f"Error: Excel file not found at {excel_file_path}")
        return {}
    except Exception as e:
        print(f"Error reading Excel file {excel_file_path}: {e}")
        return {}

    roi_geometries = {}
    required_columns = ['Box_ID', 'Longitude', 'Latitude', 'Width_degrees', 'Height_degrees']
    if not all(col in df.columns for col in required_columns):
        print(f"Error: Excel file {excel_file_path} is missing one or more required columns: {required_columns}")
        print(f"Available columns: {df.columns.tolist()}")
        return {}

    for index, row in df.iterrows():
        try:
            box_id = row['Box_ID']
            center_lon = float(row['Longitude'])
            center_lat = float(row['Latitude'])
            width_deg = float(row['Width_degrees'])
            height_deg = float(row['Height_degrees'])

            min_lon = center_lon - (width_deg / 2)
            max_lon = center_lon + (width_deg / 2)
            min_lat = center_lat - (height_deg / 2)
            max_lat = center_lat + (height_deg / 2)

            roi_name = f"{kv_type_prefix}_{box_id}"
            
            # Create an ee.Geometry.Polygon object
            # Coordinates are in EPSG:4326 (lon/lat degrees)
            # Using Counter-Clockwise (CCW) order: BL, BR, TR, TL
            coords_4326 = [
                [min_lon, min_lat],  # Bottom-left
                [max_lon, min_lat],  # Bottom-right
                [max_lon, max_lat],  # Top-right
                [min_lon, max_lat],  # Top-left
                [min_lon, min_lat]   # Close the loop
            ]
            
            geometry = ee.Geometry.Polygon(
                coords=coords_4326,
                proj='EPSG:4326',
                geodesic=False,  # Treat as planar in EPSG:4326 for consistency
                evenOdd=True    # Use even-odd rule for interior determination
            )
            roi_geometries[roi_name] = geometry
        except ValueError as ve:
            print(f"Skipping row {index+2} in {excel_file_path} (Box_ID: {row.get('Box_ID', 'N/A')}) due to data type error: {ve}. Ensure numeric values for coordinates/dimensions.")
        except Exception as e:
            print(f"Error processing row {index+2} in {excel_file_path} for Box_ID {row.get('Box_ID', 'N/A')}: {e}")
            
    return roi_geometries

def create_rois_from_coordinates_dict(coordinates_dict, resolutions=[10, 20], pixels=512):
    """
    Creates ROI geometries from a dictionary of coordinates for specified resolutions and pixel sizes.
    
    Args:
        coordinates_dict (dict): Dictionary with ROI names as keys and (longitude, latitude) tuples as values
        resolutions (list): List of resolutions in meters (default: [10, 20])
        pixels (int): Number of pixels per side for square images (default: 512)
    
    Returns:
        dict: Dictionary where keys are ROI names with resolution suffix (e.g., "ROI1_10m", "ROI1_20m")
              and values are ee.Geometry.Polygon objects
    """
    roi_geometries = {}
    
    for roi_name, (center_lon, center_lat) in coordinates_dict.items():
        try:
            center_lon = float(center_lon)
            center_lat = float(center_lat)
            
            # Validate coordinates
            if not (-180 <= center_lon <= 180):
                print(f"Warning: Invalid longitude {center_lon} for ROI {roi_name}. Skipping.")
                continue
            if not (-90 <= center_lat <= 90):
                print(f"Warning: Invalid latitude {center_lat} for ROI {roi_name}. Skipping.")
                continue
            
            for resolution in resolutions:
                # Calculate the size of the bounding box in meters
                box_size_meters = pixels * resolution
                
                # Convert meters to degrees
                # 1 degree latitude ≈ 111,319.5 meters (constant)
                # 1 degree longitude ≈ 111,319.5 * cos(latitude) meters
                lat_deg_per_meter = 1 / 111319.5
                lon_deg_per_meter = 1 / (111319.5 * math.cos(math.radians(center_lat)))
                
                # Calculate half the box size in degrees
                half_box_lat = (box_size_meters / 2) * lat_deg_per_meter
                half_box_lon = (box_size_meters / 2) * lon_deg_per_meter
                
                # Calculate bounding box coordinates
                min_lon = center_lon - half_box_lon
                max_lon = center_lon + half_box_lon
                min_lat = center_lat - half_box_lat
                max_lat = center_lat + half_box_lat
                
                # Create ROI name with resolution suffix
                roi_name_with_res = f"{roi_name}_{resolution}m"
                
                # Create coordinates in counter-clockwise order for ee.Geometry.Polygon
                coords_4326 = [
                    [min_lon, min_lat],  # Bottom-left
                    [max_lon, min_lat],  # Bottom-right
                    [max_lon, max_lat],  # Top-right
                    [min_lon, max_lat],  # Top-left
                    [min_lon, min_lat]   # Close the loop
                ]
                
                # Create ee.Geometry.Polygon object
                geometry = ee.Geometry.Polygon(
                    coords=coords_4326,
                    proj='EPSG:4326',
                    geodesic=False,
                    evenOdd=True
                )
                
                roi_geometries[roi_name_with_res] = geometry
                
                print(f"Created ROI: {roi_name_with_res} - Center: ({center_lon:.6f}, {center_lat:.6f}), "
                      f"Size: {box_size_meters}m x {box_size_meters}m ({pixels}x{pixels} pixels at {resolution}m resolution)")
                
        except ValueError as ve:
            print(f"Error processing ROI {roi_name}: Invalid coordinate values. {ve}")
        except Exception as e:
            print(f"Error processing ROI {roi_name}: {e}")
    
    return roi_geometries

def validate_and_clean_roi_images(roi_name, big_folder):
    """
    Validates images in a specific ROI by checking band counts and removes invalid images.
    
    Args:
        roi_name (str): Name of the ROI to validate
        big_folder (str): Base folder containing all ROI data
        
    Returns:
        dict: Summary of validation results with counts of invalid images removed
    """
    roi_folder = os.path.join(big_folder, roi_name)
    validation_results = {
        'roi_name': roi_name,
        'ndvi_invalid_removed': 0,
        'rvi_invalid_removed': 0,
        'era5_invalid_removed': 0,
        'needs_recrawl': False
    }
    
    if not os.path.exists(roi_folder):
        print(f"[VALIDATION] {roi_name}: ROI folder not found")
        return validation_results
    
    print(f"[VALIDATION] Starting validation for {roi_name}...")
    
    # Define validation criteria: {folder_name: expected_bands}
    validation_criteria = {
        'ndvi': 1,
        'rvi': 3,
        'era5': 2
    }
    
    total_invalid = 0
    
    for data_type, expected_bands in validation_criteria.items():
        data_folder = os.path.join(roi_folder, data_type)
        
        if not os.path.exists(data_folder):
            print(f"[VALIDATION] {roi_name}: {data_type} folder not found, skipping")
            continue
            
        # Find all .tif files in the data folder
        tif_pattern = os.path.join(data_folder, "*.tif")
        tif_files = glob.glob(tif_pattern)
        
        if not tif_files:
            print(f"[VALIDATION] {roi_name}: No .tif files found in {data_type} folder")
            continue
            
        invalid_files = []
        
        for tif_file in tif_files:
            try:
                with rasterio.open(tif_file) as dataset:
                    actual_bands = dataset.count
                    
                    if actual_bands != expected_bands:
                        print(f"[VALIDATION] {roi_name}: Invalid {data_type} image {os.path.basename(tif_file)} "
                              f"- Expected {expected_bands} bands, found {actual_bands}")
                        invalid_files.append(tif_file)
                        
            except Exception as e:
                print(f"[VALIDATION] {roi_name}: Error reading {tif_file}: {e}")
                invalid_files.append(tif_file)
        
        # Remove invalid files
        removed_count = 0
        for invalid_file in invalid_files:
            try:
                os.remove(invalid_file)
                removed_count += 1
                print(f"[VALIDATION] {roi_name}: Removed invalid {data_type} image: {os.path.basename(invalid_file)}")
            except Exception as e:
                print(f"[VALIDATION] {roi_name}: Failed to remove {invalid_file}: {e}")
        
        # Update results
        if data_type == 'ndvi':
            validation_results['ndvi_invalid_removed'] = removed_count
        elif data_type == 'rvi':
            validation_results['rvi_invalid_removed'] = removed_count
        elif data_type == 'era5':
            validation_results['era5_invalid_removed'] = removed_count
            
        total_invalid += removed_count
    
    # Mark for re-crawl if any invalid images were found
    if total_invalid > 0:
        validation_results['needs_recrawl'] = True
        print(f"[VALIDATION] {roi_name}: Total {total_invalid} invalid images removed - ROI needs re-crawling")
    else:
        print(f"[VALIDATION] {roi_name}: All images are valid")
    
    return validation_results


def validate_all_rois(all_roi_geometries, big_folder):
    """
    Validates images in all ROIs and returns a list of ROIs that need re-crawling.
    
    Args:
        all_roi_geometries (dict): Dictionary of ROI names to geometry objects
        big_folder (str): Base folder containing all ROI data
        
    Returns:
        tuple: (validation_summary, rois_needing_recrawl)
    """
    print("\n" + "="*60)
    print("STARTING IMAGE VALIDATION FOR ALL ROIs")
    print("="*60)
    
    validation_summary = []
    rois_needing_recrawl = {}
    
    for roi_name in all_roi_geometries.keys():
        validation_result = validate_and_clean_roi_images(roi_name, big_folder)
        validation_summary.append(validation_result)
        
        if validation_result['needs_recrawl']:
            rois_needing_recrawl[roi_name] = all_roi_geometries[roi_name]
    
    # Print summary
    print("\n" + "-"*60)
    print("VALIDATION SUMMARY")
    print("-"*60)
    
    total_ndvi_removed = sum(r['ndvi_invalid_removed'] for r in validation_summary)
    total_rvi_removed = sum(r['rvi_invalid_removed'] for r in validation_summary)
    total_era5_removed = sum(r['era5_invalid_removed'] for r in validation_summary)
    
    print(f"Total invalid NDVI images removed: {total_ndvi_removed}")
    print(f"Total invalid RVI images removed: {total_rvi_removed}")
    print(f"Total invalid ERA5 images removed: {total_era5_removed}")
    print(f"ROIs needing re-crawl: {len(rois_needing_recrawl)}")
    
    if rois_needing_recrawl:
        print("\nROIs that need re-crawling:")
        for roi_name in rois_needing_recrawl.keys():
            print(f"  - {roi_name}")
    
    return validation_summary, rois_needing_recrawl


def process_roi_with_validation(roi_tuple, big_folder, is_recrawl=False):
    """
    Process a single ROI and validate images after crawling.
    
    Args:
        roi_tuple (tuple): (roi_name, geometry_obj)
        big_folder (str): Base folder for data storage
        is_recrawl (bool): Whether this is a re-crawl operation
        
    Returns:
        tuple: (status_message, validation_result)
    """
    roi_name, geometry_obj = roi_tuple
    prefix = "[RE-CRAWL]" if is_recrawl else "[CRAWL]"

    # Validate geometry before heavy work
    if not isinstance(geometry_obj, ee.computedobject.ComputedObject):
        return f"[SKIP] {roi_name}: Invalid geometry object type {type(geometry_obj)}", None

    try:
        print(f"--- {prefix} [{roi_name}] Composite LST ---")
        lst_retrive(date_start_str, date_end_str, geometry_obj, roi_name, big_folder)

        # ------------------------------------------------
        # Ancillary datasets driven by composite LST dates
        # ------------------------------------------------
        lst_composite_folder = os.path.join(big_folder, roi_name, "lst")
        if os.path.isdir(lst_composite_folder):
            era5_output_folder = os.path.join(big_folder, roi_name, "era5")

            print(f"--- {prefix} [{roi_name}] ERA5 ---")
            era5_download(lst_composite_folder, era5_output_folder)
        else:
            print(f"[WARN] {roi_name}: LST composite folder not found → skip ERA5")

        # ------------------------------------------------
        # Individual datasets independent of composite list
        # ------------------------------------------------
        print(f"--- {prefix} [{roi_name}] RVI ---")
        main_rvi(start_date_ee, end_date_ee, geometry_obj, big_folder, roi_name)

        print(f"--- {prefix} [{roi_name}] NDVI ---")
        main_ndvi(start_date_ee, end_date_ee, geometry_obj, roi_name, big_folder)

        # Validate images after crawling
        print(f"--- {prefix} [{roi_name}] VALIDATING IMAGES ---")
        validation_result = validate_and_clean_roi_images(roi_name, big_folder)
        
        status = f"[DONE] {roi_name}"
        if validation_result['needs_recrawl'] and not is_recrawl:
            status += " (needs re-crawl)"
            
        return status, validation_result

    except ee.EEException as gee_err:
        return f"[GEE ERROR] {roi_name}: {gee_err}", None
    except Exception as ex:
        return f"[ERROR] {roi_name}: {ex}", None


if __name__=="__main__":
    # Initialize the Earth Engine API.
    try:
        ee.Authenticate()
        ee.Initialize(project='ee-hadat-461702-p4') # Replace 'ee-hadat' with your GEE project if different
        print("Google Earth Engine initialized successfully.")
    except Exception as e:
        print(f"Could not initialize Earth Engine: {e}")
        print("Please ensure you have authenticated and configured GEE correctly.")
        exit()

    date_start_str = '2015-01-01'
    date_end_str = '2025-01-01'
    # Using ee.Date objects for GEE functions
    start_date_ee = ee.Date(date_start_str)    
    end_date_ee = ee.Date(date_end_str)

    big_folder = "/mnt/hdd12tb/code/nhatvm/DELAG_data_retrieval/download_data_v3"
    sample_folder = "/mnt/hdd12tb/code/nhatvm/DELAG_data_retrieval/sample_data"
    
    # =============================================================================
    # NEW: Read ROIs from CSV file generated by filter_tay_nguyen_grids.py
    # =============================================================================
    csv_file_path = "/mnt/hdd12tb/code/nhatvm/DELAG_data_retrieval/tay_nguyen_filtered_grids.csv"
    
    # =============================================================================
    # HYPER-PARAMETERS FOR ROI SELECTION
    # =============================================================================
    # Use these parameters to select a subset of ROIs from the CSV file for processing.
    # This is useful for testing, debugging, or processing the full dataset in smaller chunks.

    # Set to True to activate the ROI subset selection below. 
    # If False, all ROIs from the CSV will be processed.
    SELECT_SUBSET_OF_ROIS = True

    # Define the slice of ROIs to process from the list of all available ROIs.
    # The ROIs are processed in the order they appear in the CSV file.
    #
    # Examples:
    #   - slice(0, 10)    -> Processes the first 10 ROIs (indices 0 through 9).
    #   - slice(10, 20)   -> Processes the next 10 ROIs (indices 10 through 19).
    #   - slice(None)     -> Processes all ROIs (equivalent to setting SELECT_SUBSET_OF_ROIS to False).
    #   - slice(0, None, 10) -> Processes every 10th ROI from the beginning.
    ROI_SLICE = slice(0, 5)  # <-- EDIT THIS LINE TO CHANGE THE SELECTION
    
    print("Reading ROIs from CSV file...")
    all_roi_geometries = read_rois_from_csv(csv_file_path)
    
    if not all_roi_geometries:
        print("No ROIs were found in the CSV file. Please run filter_tay_nguyen_grids.py first to generate the CSV file. Exiting.")
        exit()
    else:
        print(f"Successfully loaded {len(all_roi_geometries)} ROI geometries from CSV.")

    # Apply ROI subset selection if enabled
    if SELECT_SUBSET_OF_ROIS:
        print("\n" + "="*60)
        print("ROI SUBSET SELECTION IS ENABLED")
        print(f"Applying slice: {ROI_SLICE}")
        print("="*60)
        
        # Convert dict items to a list to apply the slice, since dicts are not subscriptable
        all_roi_items = list(all_roi_geometries.items())
        
        
        
        # Apply the slice to the list of items
        selected_roi_items = all_roi_items[slice(0, len(all_roi_items)//2+10)]
        print("**** Length of selected_roi_items: ",len(selected_roi_items))
        
        # Convert the selected list of items back to a dictionary
        all_roi_geometries = dict(selected_roi_items)
        
        if not all_roi_geometries:
            print("\n[WARNING] The selected slice resulted in 0 ROIs. Nothing to process.")
            print("Please check your ROI_SLICE parameter. Exiting.")
            exit()
            
        print(f"\nSelected {len(all_roi_geometries)} ROIs for processing:")
        for roi_name in all_roi_geometries.keys():
            print(f"  - {roi_name}")
        print("="*60 + "\n")
    
    print("Starting data retrieval for each ROI (parallel)...")

    # -------------------------------------------------------
    # INITIAL CRAWLING WITH VALIDATION
    # -------------------------------------------------------
    max_workers = min(4, len(all_roi_geometries))  # adjust as needed
    print(f"Launching ThreadPool with {max_workers} workers…")

    results = []
    validation_results = []
    
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_roi = {
            executor.submit(process_roi_with_validation, item, big_folder, False): item[0] 
            for item in all_roi_geometries.items()
        }
        
        for future in as_completed(future_to_roi):
            roi = future_to_roi[future]
            try:
                status, validation_result = future.result()
                results.append(status)
                if validation_result:
                    validation_results.append(validation_result)
                print(status)
            except Exception as exc:
                print(f"[THREAD EXCEPTION] {roi}: {exc}")

    print("\n--- Initial ROI processing complete ---")
    
    # -------------------------------------------------------
    # IDENTIFY AND RE-CRAWL ROIs WITH INVALID IMAGES
    # -------------------------------------------------------
    rois_needing_recrawl = {
        result['roi_name']: all_roi_geometries[result['roi_name']] 
        for result in validation_results 
        if result['needs_recrawl'] and result['roi_name'] in all_roi_geometries
    }
    
    if rois_needing_recrawl:
        print(f"\n" + "="*60)
        print(f"RE-CRAWLING {len(rois_needing_recrawl)} ROIs WITH INVALID IMAGES")
        print("="*60)
        
        max_recrawl_attempts = 5
        attempt = 1
        
        while rois_needing_recrawl and attempt <= max_recrawl_attempts:
            print(f"\n--- Re-crawl Attempt {attempt}/{max_recrawl_attempts} ---")
            print(f"ROIs to re-crawl: {list(rois_needing_recrawl.keys())}")
            
            recrawl_results = []
            recrawl_validation_results = []
            
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                future_to_roi = {
                    executor.submit(process_roi_with_validation, item, big_folder, True): item[0] 
                    for item in rois_needing_recrawl.items()
                }
                
                for future in as_completed(future_to_roi):
                    roi = future_to_roi[future]
                    try:
                        status, validation_result = future.result()
                        recrawl_results.append(status)
                        if validation_result:
                            recrawl_validation_results.append(validation_result)
                        print(status)
                    except Exception as exc:
                        print(f"[RE-CRAWL THREAD EXCEPTION] {roi}: {exc}")
            
            # Update the list of ROIs that still need re-crawling
            rois_needing_recrawl = {
                result['roi_name']: all_roi_geometries[result['roi_name']] 
                for result in recrawl_validation_results 
                if result['needs_recrawl'] and result['roi_name'] in all_roi_geometries
            }
            
            attempt += 1
        
        if rois_needing_recrawl:
            print(f"\n[WARNING] After {max_recrawl_attempts} attempts, {len(rois_needing_recrawl)} ROIs still have invalid images:")
            for roi_name in rois_needing_recrawl.keys():
                print(f"  - {roi_name}")
        else:
            print(f"\n[SUCCESS] All ROIs have been successfully validated after re-crawling!")
    else:
        print(f"\n[SUCCESS] All ROIs passed initial validation - no re-crawling needed!")

    print("\n--- All ROI processing and validation complete ---")
    


